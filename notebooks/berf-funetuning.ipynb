{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ead85f-3067-4910-9314-ff9d526145ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\n",
    "\n",
    "import mlflow\n",
    "from transformers import TrainerCallback\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.exceptions import MlflowException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb73d60-e149-4b62-8b57-38d724796a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pandas.read_csv('/data/Training_Data.csv')\n",
    "data_test = pandas.read_csv('/data/Query_and_Validation_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d1389ca-b6cd-4155-8337-bf0e7a07983c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_description</th>\n",
       "      <th>Category</th>\n",
       "      <th>category_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cookies cakes Chocolate Sandwich Cookies</td>\n",
       "      <td>Dry Goods &amp; Pantry Staples</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spices seasonings All-Seasons Salt</td>\n",
       "      <td>Dry Goods &amp; Pantry Staples</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robust Golden Unsweetened Oolong Tea</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frozen meals Smart Ones Classic Favorites Mini...</td>\n",
       "      <td>Fresh &amp; Perishable Items</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marinades meat preparation Green Chile Anytime...</td>\n",
       "      <td>Dry Goods &amp; Pantry Staples</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44995</th>\n",
       "      <td>hair care Keratin Oil Anti-Breakage Conditioner</td>\n",
       "      <td>Household &amp; Personal Care</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44996</th>\n",
       "      <td>ice cream ice Pineapple Mango Carrot Ice Pops</td>\n",
       "      <td>Fresh &amp; Perishable Items</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44997</th>\n",
       "      <td>Creamline Vanilla Yogurt</td>\n",
       "      <td>Fresh &amp; Perishable Items</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44998</th>\n",
       "      <td>Uncured Pepper Salami</td>\n",
       "      <td>Fresh &amp; Perishable Items</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44999</th>\n",
       "      <td>instant foods With Shrimp Ramen Noodles</td>\n",
       "      <td>Dry Goods &amp; Pantry Staples</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     product_description  \\\n",
       "0               cookies cakes Chocolate Sandwich Cookies   \n",
       "1                     spices seasonings All-Seasons Salt   \n",
       "2                   Robust Golden Unsweetened Oolong Tea   \n",
       "3      frozen meals Smart Ones Classic Favorites Mini...   \n",
       "4      marinades meat preparation Green Chile Anytime...   \n",
       "...                                                  ...   \n",
       "44995    hair care Keratin Oil Anti-Breakage Conditioner   \n",
       "44996      ice cream ice Pineapple Mango Carrot Ice Pops   \n",
       "44997                           Creamline Vanilla Yogurt   \n",
       "44998                              Uncured Pepper Salami   \n",
       "44999            instant foods With Shrimp Ramen Noodles   \n",
       "\n",
       "                         Category  category_index  \n",
       "0      Dry Goods & Pantry Staples               0  \n",
       "1      Dry Goods & Pantry Staples               0  \n",
       "2                       Beverages               3  \n",
       "3        Fresh & Perishable Items               1  \n",
       "4      Dry Goods & Pantry Staples               0  \n",
       "...                           ...             ...  \n",
       "44995   Household & Personal Care               2  \n",
       "44996    Fresh & Perishable Items               1  \n",
       "44997    Fresh & Perishable Items               1  \n",
       "44998    Fresh & Perishable Items               1  \n",
       "44999  Dry Goods & Pantry Staples               0  \n",
       "\n",
       "[45000 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a276b4f6-9b6f-4d0f-8f0a-442922a6ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_description    object\n",
       "Category               object\n",
       "category_index          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(['product_description', 'Category']).intersection(data_train.columns)) == 2\n",
    "data_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656b560-c6f0-43e5-9922-7acb737444bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f08e7a91-6062-4b59-808e-938e9f3f91ab",
   "metadata": {},
   "source": [
    "# 1. Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ebb47-5545-44ab-92c7-02b60d8e3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411bd570-e659-4a55-a6a3-ab3ab73f264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d04a3a8-509d-43b3-84d2-058e925a5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e31e32-f614-4b8e-b056-60c40935aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = data_train['Category'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(value_counts.index, value_counts.values)\n",
    "plt.xlabel('Values in Column Category')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.title('Histogram of Value Counts in Column A')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafce7aa-ffb2-4f51-a94f-978786620a51",
   "metadata": {},
   "source": [
    "There's data imbalance in labels distribution. For training we have to take it into consideration to use class_weights or oversampling/undersampling techniques\n",
    "\n",
    "Let's check input sequence len distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6675bb7-dae1-430a-bd97-26e89671b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = list()\n",
    "\n",
    "for description in data_train['product_description']:\n",
    "    # print(description)\n",
    "    num_words.append(len(description.split(' ')))\n",
    "    # break\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(num_words)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472868f-da3f-44cd-9914-0de6366b0c4d",
   "metadata": {},
   "source": [
    "input sequence lenght disctibution is fine, it's not bigger that model's `max_input_len`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20dcc5e-929e-47d7-9d10-11d6509a279f",
   "metadata": {},
   "source": [
    "# 2. Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "482a2018-9330-417b-948c-429595433bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_num_map = {\n",
    "    'Dry Goods & Pantry Staples': 0,\n",
    "    'Fresh & Perishable Items': 1,\n",
    "    'Household & Personal Care': 2,\n",
    "    'Beverages': 3,\n",
    "    'Specialty & Miscellaneous': 4\n",
    "}\n",
    "\n",
    "data_train['category_index'] = data_train.apply(lambda x: label_to_num_map[x['Category']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758d80b-8721-4026-afb7-7dc52564de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "data_to_split = data_train.sample(1000)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data_to_split['product_description'], data_to_split['category_index'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987a1d2-1cd3-4cd6-8d3b-b0a9b60f23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bde463-3a31-4895-a21d-4a22e4168021",
   "metadata": {},
   "source": [
    "# 3. Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ec7d1-e983-40a3-adac-0271949bfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetActiveRunCallback(TrainerCallback):\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        if not mlflow.active_run():\n",
    "            mlflow.start_run()\n",
    "        self.run_id = mlflow.active_run().info.run_id\n",
    "        print(f\"MLflow RUN_ID at start of training: {self.run_id}\")\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        print(f\"MLflow RUN_ID at end of training: {self.run_id}\")\n",
    "        mlflow.end_run()\n",
    "\n",
    "active_run_id_callback = GetActiveRunCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a2e92f-d6d9-42bc-8070-28b4f150d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = \"test1\"\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://mlflow:5000\"\n",
    "os.environ[\"HF_MLFLOW_LOG_ARTIFACTS\"] = \"False\"\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio_user\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio_password\"\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://minio:9000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d913171b-a9ca-433a-85bf-60bdbe41fb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f491604d0154d3bacf5f46b559226cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21c510f190a45f2bd95bd468bf2a367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a8386e14d9420fa6dbbda5d5751691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62da060ee94d4c3d9abd5e3b979ccda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'TextClassificationDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> 5\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTextClassificationDataset\u001b[49m(train_texts\u001b[38;5;241m.\u001b[39mtolist(), train_labels\u001b[38;5;241m.\u001b[39mtolist(), tokenizer)\n\u001b[1;32m      6\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m TextClassificationDataset(val_texts\u001b[38;5;241m.\u001b[39mtolist(), val_labels\u001b[38;5;241m.\u001b[39mtolist(), tokenizer)\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TextClassificationDataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_dataset = TextClassificationDataset(train_texts.tolist(), train_labels.tolist(), tokenizer)\n",
    "val_dataset = TextClassificationDataset(val_texts.tolist(), val_labels.tolist(), tokenizer)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "\n",
    "run_name = f\"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    run_name=run_name,\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    f1_for_each_class = f1_score(labels, preds, average=None)\n",
    "    # acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        # 'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_for_each_class': f1_for_each_class.tolist(),\n",
    "        'f1_min': min(f1_for_each_class),\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[active_run_id_callback]\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "trainer.save_model(\"./text_classification_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad0136-ff2a-4096-a65d-4dc189eceeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlflow.active_run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787559dd-6ba1-4a35-bc86-f0fc59eb13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = active_run_id_callback.run_id\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faea7980-7f00-4c24-b07b-8118ec2eb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "run_id = \"9acee285129b429ba9243103cac82ff4\"  # Replace with the run ID of your model\n",
    "# artifacts = client.list_artifacts(run_id,) #path=\"model-checkpoints\")\n",
    "\n",
    "# print(artifacts)\n",
    "# # Find the best checkpoint based on custom logic\n",
    "# best_checkpoint_path = None\n",
    "# for artifact in artifacts:\n",
    "#     # if \"best\" in artifact.path:  # Example logic to find the best\n",
    "#     #     best_checkpoint_path = artifact.path\n",
    "#     #     break\n",
    "#     print(artifact)\n",
    "#     break\n",
    "\n",
    "# print(f\"Best checkpoint: {best_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a2e3bbf-bbba-42d2-afd3-518e5fc3fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.get_run(run_id).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c4feb31-1a02-46c7-af23-39b1fddb2e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint-6750'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_best_step(run_id, metric):\n",
    "    metric_history = client.get_metric_history(run_id, metric)\n",
    "    metric_list = [i.value for i in metric_history]\n",
    "    max_metric_index = np.argmax(metric_list)\n",
    "\n",
    "    f1_history = client.get_metric_history(run_id, 'eval_f1')\n",
    "    f1_min_history = client.get_metric_history(run_id, 'eval_f1_min')\n",
    "\n",
    "    return {\n",
    "        \"best_checkpoint\": f\"checkpoint-{metric_history[max_metric_index].step}\", \n",
    "        \"best_f1\": f1_history[max_metric_index].value,\n",
    "        \"best_f1_min\": f1_min_history[max_metric_index].value\n",
    "    }\n",
    "\n",
    "# def find_best_checkpoint_path(run_id, metric):\n",
    "#     return f\"checkpoint-{get_best_step(run_id, metric).step}\"\n",
    "\n",
    "def find_best_f1(run_id, metric):\n",
    "    return get_best_step(run_id, metric)\n",
    "\n",
    "checkpoint_name = get_best_step(run_id, 'eval_f1_min')['best_checkpoint']\n",
    "checkpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "581880b0-d5de-4203-a278-d4a9df57282f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_checkpoint': 'checkpoint-6750',\n",
       " 'best_f1': 0.983252622335609,\n",
       " 'best_f1_min': 0.9487418452935694}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_step(run_id, 'eval_f1_min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bf99ba8-935c-481f-a2a8-0db326aeb242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Metric: key='eval_f1', step=2250, timestamp=1737723531643, value=0.9801766650835574>,\n",
       " <Metric: key='eval_f1', step=4500, timestamp=1737723974475, value=0.9824630949240958>,\n",
       " <Metric: key='eval_f1', step=6750, timestamp=1737724402163, value=0.983252622335609>,\n",
       " <Metric: key='eval_f1', step=9000, timestamp=1737724824930, value=0.9814570895321665>,\n",
       " <Metric: key='eval_f1', step=11250, timestamp=1737725248665, value=0.9833628672529641>,\n",
       " <Metric: key='eval_f1', step=13500, timestamp=1737725679137, value=0.9832534768255637>,\n",
       " <Metric: key='eval_f1', step=15750, timestamp=1737726121849, value=0.9806785301463666>,\n",
       " <Metric: key='eval_f1', step=18000, timestamp=1737726562401, value=0.9823689480603836>,\n",
       " <Metric: key='eval_f1', step=20250, timestamp=1737726999773, value=0.9830448669181506>,\n",
       " <Metric: key='eval_f1', step=22500, timestamp=1737727453717, value=0.9830424144028685>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_f1(run_id, 'eval_f1_min')\n",
    "client.get_metric_history(run_id, 'eval_f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df7a9bf9-11e3-47fd-bfec-6050a3764ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588149d09ead4847ac4b78d4b9a2ed28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artifacts_download_dir = os.path.join(f'/tmp/{run_id}')\n",
    "\n",
    "if not os.path.exists(artifacts_download_dir):\n",
    "    os.makedirs(artifacts_download_dir)\n",
    "\n",
    "try:\n",
    "    client.download_artifacts(run_id, checkpoint_name, artifacts_download_dir)\n",
    "except MlflowException as e:\n",
    "    print(f\"Exception occured: {e}\") \n",
    "\n",
    "    # s3://mlflow/1/9acee285129b429ba9243103cac82ff4/artifacts/checkpoint-6750"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d84ee48-9e5a-4730-961e-7cb4d2c510a6",
   "metadata": {},
   "source": [
    "# 4. Load best model from checkpoint and evaluate it on test set with human feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c85c083-b804-4c9e-b1d8-d667769a5154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_checkpoint_path = os.path.join(artifacts_download_dir, checkpoint_name, \"artifacts\", checkpoint_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer_loaded = BertTokenizer.from_pretrained(saved_checkpoint_path)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(saved_checkpoint_path).to(device)\n",
    "model_loaded.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64d85efd-4393-443c-b2c2-cb279b414959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Some text\"\n",
    "# texts = [\"text1\", \"text2\"]\n",
    "# texts = [\"text1\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# input_ids = tokenizer_loaded(texts, \n",
    "#                  max_length=128,\n",
    "#             padding='max_length',\n",
    "#             truncation=True,\n",
    "#             return_tensors=\"pt\").to(device)\n",
    "\n",
    "# # model_loaded(input_ids)\n",
    "# preds = model_loaded(**input_ids)\n",
    "# # preds.logits, \n",
    "# pred_idxs = torch.argmax(preds.logits, dim=1)\n",
    "# pred_idxs.cpu().numpy().tolist()\n",
    "\n",
    "# # def predict_file(filepath):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6b77a03-d4da-47c4-a358-53ff7719a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_batch(tokenizer, model, batch):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    input_ids = tokenizer(batch, \n",
    "              max_length=128,\n",
    "              padding='max_length',\n",
    "              truncation=True,\n",
    "              return_tensors=\"pt\").to(device)\n",
    "    preds = model(**input_ids)\n",
    "    return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "\n",
    "def process_in_batches(elements, batch_size):\n",
    "    \"\"\"\n",
    "    Iterates through a list in batches of size N.\n",
    "\n",
    "    :param elements: List of elements to process.\n",
    "    :param batch_size: Size of each batch.\n",
    "    \"\"\"\n",
    "    predictions_combined = list()\n",
    "    for i in range(0, len(elements), batch_size):\n",
    "        batch = elements[i:i + batch_size]\n",
    "        # Process the current batch\n",
    "        # print(f\"Processing batch: {batch}\")\n",
    "        # Add your processing logic here\n",
    "        batch_prediction = predict_on_batch(tokenizer_loaded, model_loaded, batch)\n",
    "        predictions_combined.extend(batch_prediction.cpu().numpy().astype(np.int32).tolist())\n",
    "\n",
    "    return predictions_combined\n",
    "\n",
    "predictions = process_in_batches(data_test['product_description'].values.tolist(), 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c4476f4-eda3-490f-9f2d-0b1ca2840575",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_copy = data_test.copy()\n",
    "data_test_copy['predictions'] = predictions\n",
    "data_test_copy['category_index'] = data_test_copy.apply(lambda x: label_to_num_map[x['HUMAN_VERIFIED_Category']] \n",
    "                                                        if not pandas.isnull(x['HUMAN_VERIFIED_Category']) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29436187-f333-4726-af7b-23946ae47d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_description</th>\n",
       "      <th>HUMAN_VERIFIED_Category</th>\n",
       "      <th>predictions</th>\n",
       "      <th>category_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fair Trade 100% Pure Organic Honey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organic Balsamic Vinegar Of Modena</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheesecake, Chocolate Truffle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>White Multifold Towels</td>\n",
       "      <td>Household &amp; Personal Care</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sourdough Deli Bread</td>\n",
       "      <td>Fresh &amp; Perishable Items</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product_description    HUMAN_VERIFIED_Category  predictions  \\\n",
       "0  Fair Trade 100% Pure Organic Honey                        NaN            0   \n",
       "1  Organic Balsamic Vinegar Of Modena                        NaN            0   \n",
       "2       Cheesecake, Chocolate Truffle                        NaN            1   \n",
       "3              White Multifold Towels  Household & Personal Care            2   \n",
       "4                Sourdough Deli Bread   Fresh & Perishable Items            1   \n",
       "\n",
       "   category_index  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             2.0  \n",
       "4             1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e29e6640-384b-478a-9f8b-2f3072ee5975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95588235, 0.9380531 , 0.97129187, 0.9623431 , 0.7816092 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1_score(y_true, y_pred, average=None)\n",
    "y_true = data_test_copy[~pandas.isnull(data_test_copy['HUMAN_VERIFIED_Category'])]['category_index']\n",
    "y_pred = data_test_copy[~pandas.isnull(data_test_copy['HUMAN_VERIFIED_Category'])]['predictions']\n",
    "\n",
    "f1_score(y_true, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce08ff7-6301-4626-8009-34b075a9a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.isnull(data_test_copy.loc[0]['HUMAN_VERIFIED_Category'])\n",
    "data_test_copy[~pandas.isnull(data_test_copy['HUMAN_VERIFIED_Category'])]\n",
    "type(data_test_copy.loc[0]['HUMAN_VERIFIED_Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8701dec0-5bdc-40e9-a0f7-e9decb31f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"test1\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(experiment)\n",
    "# Find the best run based on your target metric\n",
    "best_run = None\n",
    "best_metric = float('inf')  # or '-inf' for maximizing metrics\n",
    "for run in mlflow.search_runs(experiment_ids=[experiment.experiment_id]):\n",
    "    print(run)\n",
    "    metric_value = run.data.metrics['validation_loss']  # Replace with your metric\n",
    "    if metric_value < best_metric:  # Adjust comparison based on your objective\n",
    "        best_metric = metric_value\n",
    "        best_run = run\n",
    "\n",
    "# Get the checkpoint path from the best run's artifacts\n",
    "if best_run:\n",
    "    checkpoint_path = f\"{best_run.info.artifact_uri}/checkpoints\"\n",
    "    print(f\"Best checkpoint path: {checkpoint_path}\")\n",
    "    # model = BertForSequenceClassification.from_pretrained(checkpoint_path)\n",
    "else:\n",
    "    print(\"No suitable runs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f13699-124c-4e7f-a322-570065868046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "task = \"text-classification\"\n",
    "\n",
    "my_pipeline = transformers.pipeline(\n",
    "    task=task,\n",
    "    model=trainer.model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1bd1f-fe53-4a23-9d09-54e1131f0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline.predict(\"Sourdough Deli Bread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331e671-9553-4f71-8f87-a5639a7558f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.log_model(my_pipeline, artifact_path=\"model\", registered_model_name=\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d9fe5-f680-4e5d-8dd7-8e99d0db0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mlflow.register_model(\n",
    "    \"runs:/9acee285129b429ba9243103cac82ff4/checkpoint-6750\", \"bert-test-inference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded34fa9-365b-4ade-8a86-f99454f7d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f76e30-6149-4baa-879d-c48e5dd98616",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pipeline = mlflow.transformers.load_model(\n",
    "    model_info.model_uri, return_type=\"pipeline\", torch_dtype=torch.float64\n",
    ")\n",
    "\n",
    "print(loaded_pipeline.torch_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c29681-6ee6-4186-ac0a-36af2c47a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/9acee285129b429ba9243103cac82ff4/checkpoint-6750'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "# import pandas as pd\n",
    "loaded_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32517b0-3b4b-4f49-8aab-e134d7be6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model.predict(data_test)\n",
    "loaded_model.predict(\"cookies cookies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b9a7cf-b289-4587-8f29-52a2ceb23d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"car\"\n",
    "train_dataset.tokenizer(\n",
    "            text,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837a869-2320-4e51-a20d-37ea43d0a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"car Car cat\"\n",
    "train_dataset.tokenizer(\n",
    "            text,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34315413-e94a-40c9-b433-d72c3f24ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4751a-d733-4fd1-a672-447007eb83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e55f1-af11-4253-86c4-b4d2087eaec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['HUMAN_VERIFIED_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c695b-b75e-41c7-91a6-68e36526eabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed1644-2036-4570-97cd-4ef074bbb159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
