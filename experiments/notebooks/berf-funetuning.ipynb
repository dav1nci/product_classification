{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ead85f-3067-4910-9314-ff9d526145ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\n",
    "\n",
    "import mlflow\n",
    "from transformers import TrainerCallback\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.exceptions import MlflowException\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb73d60-e149-4b62-8b57-38d724796a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pandas.read_csv('/data/Training_Data.csv')\n",
    "data_test = pandas.read_csv('/data/Query_and_Validation_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e7a91-6062-4b59-808e-938e9f3f91ab",
   "metadata": {},
   "source": [
    "# 1. Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ebb47-5545-44ab-92c7-02b60d8e3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411bd570-e659-4a55-a6a3-ab3ab73f264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9afda3-81af-495f-a167-d5ddbe78cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d04a3a8-509d-43b3-84d2-058e925a5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e31e32-f614-4b8e-b056-60c40935aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = data_train['Category'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(value_counts.index, value_counts.values)\n",
    "plt.xlabel('Values in Column Category')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.title('Histogram of Value Counts in Column A')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafce7aa-ffb2-4f51-a94f-978786620a51",
   "metadata": {},
   "source": [
    "There's data imbalance in labels distribution. For training we have to take it into consideration to use class_weights or oversampling/undersampling techniques\n",
    "\n",
    "Let's check input sequence len distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6675bb7-dae1-430a-bd97-26e89671b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = list()\n",
    "\n",
    "for description in data_train['product_description']:\n",
    "    # print(description)\n",
    "    num_words.append(len(description.split(' ')))\n",
    "    # break\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(num_words)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472868f-da3f-44cd-9914-0de6366b0c4d",
   "metadata": {},
   "source": [
    "input sequence lenght disctibution is fine, it's not bigger that model's `max_input_len`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20dcc5e-929e-47d7-9d10-11d6509a279f",
   "metadata": {},
   "source": [
    "# 2. Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a2018-9330-417b-948c-429595433bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_num_map = {\n",
    "    'Dry Goods & Pantry Staples': 0,\n",
    "    'Fresh & Perishable Items': 1,\n",
    "    'Household & Personal Care': 2,\n",
    "    'Beverages': 3,\n",
    "    'Specialty & Miscellaneous': 4\n",
    "}\n",
    "\n",
    "data_train['category_index'] = data_train.apply(lambda x: label_to_num_map[x['Category']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758d80b-8721-4026-afb7-7dc52564de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "data_to_split = data_train#.sample(1000)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data_to_split['product_description'], data_to_split['category_index'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987a1d2-1cd3-4cd6-8d3b-b0a9b60f23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bde463-3a31-4895-a21d-4a22e4168021",
   "metadata": {},
   "source": [
    "# 3. Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ec7d1-e983-40a3-adac-0271949bfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetActiveRunCallback(TrainerCallback):\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        if not mlflow.active_run():\n",
    "            mlflow.start_run()\n",
    "        self.run_id = mlflow.active_run().info.run_id\n",
    "        print(f\"MLflow RUN_ID at start of training: {self.run_id}\")\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        print(f\"MLflow RUN_ID at end of training: {self.run_id}\")\n",
    "        mlflow.end_run()\n",
    "\n",
    "active_run_id_callback = GetActiveRunCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2e92f-d6d9-42bc-8070-28b4f150d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = \"test1\"\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://mlflow:5000\"\n",
    "os.environ[\"HF_MLFLOW_LOG_ARTIFACTS\"] = \"False\"\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio_user\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio_password\"\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://minio:9000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913171b-a9ca-433a-85bf-60bdbe41fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedBERT(BertForSequenceClassification):\n",
    "    def __init__(self, config, class_weights):\n",
    "        super().__init__(config)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, outputs, labels):\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(weight=self.class_weights.to(outputs.logits.device))\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        return loss\n",
    "\n",
    "# Calculate class weights\n",
    "labels = data_train['category_index']\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',  \n",
    "    classes=np.array(range(5)), \n",
    "    y=labels\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "# class_weights\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_dataset = TextClassificationDataset(train_texts.tolist(), train_labels.tolist(), tokenizer)\n",
    "val_dataset = TextClassificationDataset(val_texts.tolist(), val_labels.tolist(), tokenizer)\n",
    "\n",
    "# model = BertForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "model = WeightedBERT.from_pretrained(model_name, num_labels=5, class_weights=class_weights)\n",
    "\n",
    "run_name = f\"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=7,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    run_name=run_name,\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    f1_for_each_class = f1_score(labels, preds, average=None)\n",
    "    # acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        # 'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_for_each_class': f1_for_each_class.tolist(),\n",
    "        'f1_min': min(f1_for_each_class),\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[active_run_id_callback]\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "trainer.save_model(\"./text_classification_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e7755-84e1-46af-9f50-97e150d40b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()  # Clear GPU memory\n",
    "gc.collect()  # Collect unused Python objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad0136-ff2a-4096-a65d-4dc189eceeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlflow.active_run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787559dd-6ba1-4a35-bc86-f0fc59eb13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = active_run_id_callback.run_id\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea7980-7f00-4c24-b07b-8118ec2eb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "run_id = \"9acee285129b429ba9243103cac82ff4\"  # Replace with the run ID of your model\n",
    "# run_id = \"839e49b73ab448be98ec082588d7625e\"  # Replace with the run ID of your model\n",
    "# artifacts = client.list_artifacts(run_id,) #path=\"model-checkpoints\")\n",
    "\n",
    "# print(artifacts)\n",
    "# # Find the best checkpoint based on custom logic\n",
    "# best_checkpoint_path = None\n",
    "# for artifact in artifacts:\n",
    "#     # if \"best\" in artifact.path:  # Example logic to find the best\n",
    "#     #     best_checkpoint_path = artifact.path\n",
    "#     #     break\n",
    "#     print(artifact)\n",
    "#     break\n",
    "\n",
    "# print(f\"Best checkpoint: {best_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e3bbf-bbba-42d2-afd3-518e5fc3fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.get_run(run_id).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4feb31-1a02-46c7-af23-39b1fddb2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_best_step(run_id, metric):\n",
    "    metric_history = client.get_metric_history(run_id, metric)\n",
    "    metric_list = [i.value for i in metric_history]\n",
    "    max_metric_index = np.argmax(metric_list)\n",
    "\n",
    "    f1_history = client.get_metric_history(run_id, 'eval_f1')\n",
    "    f1_min_history = client.get_metric_history(run_id, 'eval_f1_min')\n",
    "\n",
    "    return {\n",
    "        \"best_checkpoint\": f\"checkpoint-{metric_history[max_metric_index].step}\", \n",
    "        \"best_f1\": f1_history[max_metric_index].value,\n",
    "        \"best_f1_min\": f1_min_history[max_metric_index].value\n",
    "    }\n",
    "\n",
    "# def find_best_checkpoint_path(run_id, metric):\n",
    "#     return f\"checkpoint-{get_best_step(run_id, metric).step}\"\n",
    "\n",
    "def find_best_f1(run_id, metric):\n",
    "    return get_best_step(run_id, metric)\n",
    "\n",
    "checkpoint_name = get_best_step(run_id, 'eval_f1_min')['best_checkpoint']\n",
    "checkpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581880b0-d5de-4203-a278-d4a9df57282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_best_step(run_id, 'eval_f1_min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf99ba8-935c-481f-a2a8-0db326aeb242",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_f1(run_id, 'eval_f1_min')\n",
    "client.get_metric_history(run_id, 'eval_f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a9bf9-11e3-47fd-bfec-6050a3764ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_download_dir = os.path.join(f'/tmp/{run_id}')\n",
    "\n",
    "if not os.path.exists(artifacts_download_dir):\n",
    "    os.makedirs(artifacts_download_dir)\n",
    "\n",
    "try:\n",
    "    client.download_artifacts(run_id, checkpoint_name, artifacts_download_dir)\n",
    "except MlflowException as e:\n",
    "    print(f\"Exception occured: {e}\") \n",
    "\n",
    "    # s3://mlflow/1/9acee285129b429ba9243103cac82ff4/artifacts/checkpoint-6750"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d84ee48-9e5a-4730-961e-7cb4d2c510a6",
   "metadata": {},
   "source": [
    "# 4. Load best model from checkpoint and evaluate it on test set with human feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85c083-b804-4c9e-b1d8-d667769a5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_checkpoint_path = os.path.join(artifacts_download_dir, checkpoint_name, \"artifacts\", checkpoint_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer_loaded = BertTokenizer.from_pretrained(saved_checkpoint_path)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(saved_checkpoint_path).to(device)\n",
    "model_loaded.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d85efd-4393-443c-b2c2-cb279b414959",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Some text\"\n",
    "texts = [\"text1\", \"text2\"]\n",
    "texts = [\"text1\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_ids = tokenizer_loaded(texts, \n",
    "                 max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\").to(device)\n",
    "\n",
    "# model_loaded(input_ids)\n",
    "preds = model_loaded(**input_ids)\n",
    "# preds.logits, \n",
    "pred_idxs = torch.argmax(preds.logits, dim=1)\n",
    "pred_idxs.cpu().numpy().tolist()\n",
    "\n",
    "# def predict_file(filepath):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b77a03-d4da-47c4-a358-53ff7719a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_batch(tokenizer, model, batch):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    input_ids = tokenizer(batch, \n",
    "              max_length=128,\n",
    "              padding='max_length',\n",
    "              truncation=True,\n",
    "              return_tensors=\"pt\").to(device)\n",
    "    preds = model(**input_ids)\n",
    "    return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "\n",
    "def process_in_batches(elements, batch_size):\n",
    "    \"\"\"\n",
    "    Iterates through a list in batches of size N.\n",
    "\n",
    "    :param elements: List of elements to process.\n",
    "    :param batch_size: Size of each batch.\n",
    "    \"\"\"\n",
    "    predictions_combined = list()\n",
    "    for i in range(0, len(elements), batch_size):\n",
    "        batch = elements[i:i + batch_size]\n",
    "        # Process the current batch\n",
    "        # print(f\"Processing batch: {batch}\")\n",
    "        # Add your processing logic here\n",
    "        batch_prediction = predict_on_batch(tokenizer_loaded, model_loaded, batch)\n",
    "        predictions_combined.extend(batch_prediction.cpu().numpy().astype(np.int32).tolist())\n",
    "\n",
    "    return predictions_combined\n",
    "\n",
    "def get_class_titles(labelmap, class_values):\n",
    "    value_to_title = {value: title for title, value in labelmap.items()}\n",
    "    class_titles = [value_to_title.get(value, \"Unknown\") for value in class_values]\n",
    "\n",
    "    return class_titles\n",
    "\n",
    "predictions = process_in_batches(data_test['product_description'].values.tolist(), 64)\n",
    "get_class_titles(label_to_num_map, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4476f4-eda3-490f-9f2d-0b1ca2840575",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_copy = data_test.copy()\n",
    "data_test_copy['predictions'] = predictions\n",
    "data_test_copy['category_index'] = data_test_copy.apply(lambda x: label_to_num_map[x['HUMAN_VERIFIED_Category']] \n",
    "                                                        if not pandas.isnull(x['HUMAN_VERIFIED_Category']) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29436187-f333-4726-af7b-23946ae47d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e6640-384b-478a-9f8b-2f3072ee5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score(y_true, y_pred, average=None)\n",
    "y_true = data_test_copy[~pandas.isnull(data_test_copy['HUMAN_VERIFIED_Category'])]['category_index']\n",
    "y_pred = data_test_copy[~pandas.isnull(data_test_copy['HUMAN_VERIFIED_Category'])]['predictions']\n",
    "\n",
    "f1_score(y_true, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce08ff7-6301-4626-8009-34b075a9a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.isnull(data_test_copy.loc[0]['HUMAN_VERIFIED_Category'])\n",
    "data_test_copy[~pandas.isnull(data_test_copy['HUMAN_VERIFIED_Category'])]\n",
    "type(data_test_copy.loc[0]['HUMAN_VERIFIED_Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8701dec0-5bdc-40e9-a0f7-e9decb31f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"test1\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(experiment)\n",
    "# Find the best run based on your target metric\n",
    "best_run = None\n",
    "best_metric = float('inf')  # or '-inf' for maximizing metrics\n",
    "for run in mlflow.search_runs(experiment_ids=[experiment.experiment_id]):\n",
    "    print(run)\n",
    "    metric_value = run.data.metrics['validation_loss']  # Replace with your metric\n",
    "    if metric_value < best_metric:  # Adjust comparison based on your objective\n",
    "        best_metric = metric_value\n",
    "        best_run = run\n",
    "\n",
    "# Get the checkpoint path from the best run's artifacts\n",
    "if best_run:\n",
    "    checkpoint_path = f\"{best_run.info.artifact_uri}/checkpoints\"\n",
    "    print(f\"Best checkpoint path: {checkpoint_path}\")\n",
    "    # model = BertForSequenceClassification.from_pretrained(checkpoint_path)\n",
    "else:\n",
    "    print(\"No suitable runs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f13699-124c-4e7f-a322-570065868046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "task = \"text-classification\"\n",
    "\n",
    "my_pipeline = transformers.pipeline(\n",
    "    task=task,\n",
    "    model=trainer.model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1bd1f-fe53-4a23-9d09-54e1131f0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline.predict(\"Sourdough Deli Bread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331e671-9553-4f71-8f87-a5639a7558f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.log_model(my_pipeline, artifact_path=\"model\", registered_model_name=\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d9fe5-f680-4e5d-8dd7-8e99d0db0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mlflow.register_model(\n",
    "    \"runs:/9acee285129b429ba9243103cac82ff4/checkpoint-6750\", \"bert-test-inference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded34fa9-365b-4ade-8a86-f99454f7d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f76e30-6149-4baa-879d-c48e5dd98616",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pipeline = mlflow.transformers.load_model(\n",
    "    model_info.model_uri, return_type=\"pipeline\", torch_dtype=torch.float64\n",
    ")\n",
    "\n",
    "print(loaded_pipeline.torch_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c29681-6ee6-4186-ac0a-36af2c47a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/9acee285129b429ba9243103cac82ff4/checkpoint-6750'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "# import pandas as pd\n",
    "loaded_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32517b0-3b4b-4f49-8aab-e134d7be6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model.predict(data_test)\n",
    "loaded_model.predict(\"cookies cookies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b9a7cf-b289-4587-8f29-52a2ceb23d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"car\"\n",
    "train_dataset.tokenizer(\n",
    "            text,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837a869-2320-4e51-a20d-37ea43d0a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"car Car cat\"\n",
    "train_dataset.tokenizer(\n",
    "            text,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34315413-e94a-40c9-b433-d72c3f24ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4751a-d733-4fd1-a672-447007eb83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e55f1-af11-4253-86c4-b4d2087eaec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['HUMAN_VERIFIED_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c695b-b75e-41c7-91a6-68e36526eabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed1644-2036-4570-97cd-4ef074bbb159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
